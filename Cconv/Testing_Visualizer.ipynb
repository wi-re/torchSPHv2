{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c226c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import argparse\n",
    "import yaml\n",
    "from torch_geometric.nn import radius\n",
    "from torch.optim import Adam\n",
    "import torch.autograd.profiler as profiler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from rbfConv import RbfConv\n",
    "# from dataset import compressedFluidDataset, prepareData\n",
    "\n",
    "import inspect\n",
    "import re\n",
    "def debugPrint(x):\n",
    "    frame = inspect.currentframe().f_back\n",
    "    s = inspect.getframeinfo(frame).code_context[0]\n",
    "    r = re.search(r\"\\((.*)\\)\", s).group(1)\n",
    "    print(\"{} [{}] = {}\".format(r,type(x).__name__, x))\n",
    "%matplotlib notebook\n",
    "import copy\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import argparse\n",
    "import yaml\n",
    "from torch_geometric.nn import radius\n",
    "from torch.optim import Adam\n",
    "import torch.autograd.profiler as profiler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from rbfConv import RbfConv\n",
    "from dataset import compressedFluidDataset, prepareData\n",
    "\n",
    "import inspect\n",
    "import re\n",
    "def debugPrint(x):\n",
    "    frame = inspect.currentframe().f_back\n",
    "    s = inspect.getframeinfo(frame).code_context[0]\n",
    "    r = re.search(r\"\\((.*)\\)\", s).group(1)\n",
    "    print(\"{} [{}] = {}\".format(r,type(x).__name__, x))\n",
    "\n",
    "\n",
    "import tomli\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 0\n",
    "\n",
    "\n",
    "import random \n",
    "import numpy as np\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "# print(torch.cuda.device_count())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print('running on: ', device)\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from cutlass import *\n",
    "from rbfConv import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from datautils import *\n",
    "# from sphUtils import *\n",
    "from lossFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23265426",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from plotting import *\n",
    "plt.style.use('dark_background')\n",
    "# plt.style.use('default')\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d15a0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# from itertools import permutations\n",
    "\n",
    "# options_x = ['rbf square', 'rbf linear', 'rbf bump', 'rbf spiky', 'rbf cubic_spline', 'rbf gaussian', 'fourier', 'chebyshev']\n",
    "# options_y = options_x\n",
    "\n",
    "# options_x = ['-x chebyshev -y chebyshev', '-x chebyshev -y fourier', '-x linear -y linear', '-x \"rbf cubic_spline\" -y \"rbf cubic_spline\"', '-x \"rbf gaussian\" -y \"rbf gaussian\"']\n",
    "# options_y = ['-cmap cartesian', '-cmap polar', '-cmap preserving']\n",
    "\n",
    "# options_x = ['-n 2 -m 2','-n 4 -m 4','-n 5 -m 5','-n 9 -m 9','-n 15 -m 15','-n 31 -m 31']\n",
    "# options_y = ['-w \"Wendland2\"','-w \"Wendland2_1D\"','-w \"Wendland4\"','-w \"cubicSpline\"','-w \"none\"','-w \"none\"','-w \"none\"']\n",
    "\n",
    "# combinations = []\n",
    "\n",
    "# for x in options_x:\n",
    "#     for y in options_y:\n",
    "#         combinations.append((x,y))\n",
    "\n",
    "    \n",
    "# # debugPrint(len(combinations))\n",
    "\n",
    "\n",
    "# for x,y in combinations:\n",
    "#     print(\"clear && python densityNetTraining.py --epochs=25 -n 9 -m 9 -w 'none' %s %s\" % ( x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84148b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57768719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulationFiles [list] = ['/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-23-46.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-08-20.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-03-31.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-18-34.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-39-18.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-28-47.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-21-09.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-05-55.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-13-30.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-31-28.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-34-07.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-01-01.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-36-42.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-16-02.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-10-55.hdf5', '/home/winchenbach/servus05/dev/datasets/generative2D/test/generative - 2023-03-13_10-26-18.hdf5']\n"
     ]
    }
   ],
   "source": [
    "basePath = '~/servus05/dev/datasets/generative2D/train'\n",
    "basePath = '~/servus05/dev/datasets/generative2D/test'\n",
    "# basePath = '/mnt/data/datasets/generative2D/train'\n",
    "basePath = os.path.expanduser(basePath)\n",
    "\n",
    "simulationFiles = [basePath + '/' + f for f in os.listdir(basePath) if f.endswith('.hdf5')]\n",
    "debugPrint(simulationFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fd54286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d34d1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "which_x = 'rbf_x'\n",
    "which_y = 'windowFunction'\n",
    "which_z = 'networkSeed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ade86e29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "# trainFolder = '/mnt/c/Users/Rimuru/trainingData'\n",
    "trainFolder = '~/trainingdata_2D_deltaSPH_001'\n",
    "trainFolder = '~/servus05/dev/torchSPH2/Cconv/trainingDataPentecoste'\n",
    "trainFolder = '~/servus05/dev/torchSPH2/Cconv/paperData_ablation_windowFunctions'\n",
    "trainFolder = '~/servus05/dev/torchSPH2/Cconv/paperData_ablation_seedVariance'\n",
    "trainFolder = '~/servus05/dev/torchSPH2/Cconv/paperData_ablation_coordinateMapping'\n",
    "trainFolder = '~/servus05/dev/torchSPH2/Cconv/paperData_ablation_fourierTerms'\n",
    "\n",
    "\n",
    "\n",
    "# trainFolder = '~/servus03/torchSPH2/Cconv/trainingData'\n",
    "# trainFolder = '~/servus03/torchSPH2/Cconv/trainingDataWindows'\n",
    "# trainFolder = '~/servus03/torchSPH2/Cconv/trainingAdjusted'\n",
    "# trainFolder = '~/servus03/torchSPH2/Cconv/trainingDataNormalization'\n",
    "# trainFolder = '~/servus05/dev/torchSPH2/Cconv/trainingDataSeedVariance'\n",
    "# trainFolder = '~/servus05/dev/torchSPH2/Cconv/trainingDataLongEpoch'\n",
    "trainFolder = os.path.expanduser(trainFolder)\n",
    "# subfolders = [ f.path for f in os.scandir(trainFolder) if (f.is_dir() and 'None' not in f.path)]\n",
    "subfolders = [ f.path for f in os.scandir(trainFolder) if (f.is_dir())]\n",
    "# subfolders = [ f.path for f in os.scandir('./trainingDataBasisFunctions8x8') if f.is_dir() ]\n",
    "print(len(subfolders))\n",
    "\n",
    "subfolders = [s for s in subfolders if os.path.exists(s + '/results.json')]\n",
    "# print(len(subfolders))\n",
    "\n",
    "# dataDict = {}\n",
    "\n",
    "# # subfolders = [subfolders[0]]\n",
    "# for s in tqdm(subfolders):\n",
    "#     with open(\"%s/results.json\" % s, \"r\") as read_file:\n",
    "#         decodedArray = json.load(read_file)\n",
    "#         dataDict[s] = decodedArray\n",
    "# #         print(decodedArray['hyperParameters'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d18aa055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd sgn,fourier odd sgn] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_07-09-04 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[ffourier,ffourier] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_12-36-17 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[ffourier,ffourier] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_17-00-56 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd lin,fourier odd lin] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_13-05-51 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[dmcf,linear] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_01-35-22 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd lin,fourier odd lin] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_06-25-04 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier even,fourier even] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_14-07-00 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd lin,fourier odd lin] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_22-38-44 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier,fourier] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_00-37-47 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd lin,fourier odd lin] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_05-55-17 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[dmcf,linear] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_15-06-55 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier,fourier] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_09-20-26 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[ffourier,ffourier] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_02-48-35 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier,fourier] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_01-58-40 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[ffourier,ffourier] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_09-20-26 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[ffourier,ffourier] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_01-56-46 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd lin,fourier odd lin] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_15-03-02 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd lin,fourier odd lin] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_13-52-17 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[dmcf,linear] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_17-52-00 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd,fourier odd] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_19-44-07 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier even,fourier even] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_19-56-31 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[ffourier,ffourier] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_18-42-57 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[ffourier,ffourier] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_02-47-50 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[ffourier,ffourier] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_10-07-49 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[dmcf,linear] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_08-36-55 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd lin,fourier odd lin] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_22-39-25 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd sgn,fourier odd sgn] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_14-53-37 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier even,fourier even] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_22-12-27 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd lin,fourier odd lin] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_12-04-37 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier even,fourier even] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_04-21-21 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd,fourier odd] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_19-10-12 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier,fourier] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_10-21-08 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier,fourier] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_09-25-22 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[dmcf,linear] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_07-23-49 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 5, 5] rbf=[ffourier 5,ffourier 5] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_02-37-48 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[dmcf,linear] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_14-23-59 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd sgn,fourier odd sgn] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_06-28-49 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 5, 5] rbf=[ffourier 5,ffourier 5] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_18-33-44 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd,fourier odd] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_03-41-52 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier,fourier] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_02-35-45 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd,fourier odd] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_11-08-18 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier even,fourier even] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_11-19-55 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd,fourier odd] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_12-37-57 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[dmcf,linear] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_23-43-10 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 5, 5] rbf=[ffourier 5,ffourier 5] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_08-03-31 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd sgn,fourier odd sgn] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_16-44-39 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd sgn,fourier odd sgn] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_06-58-47 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier even,fourier even] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_13-11-24 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier even,fourier even] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_13-03-46 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 5, 5] rbf=[ffourier 5,ffourier 5] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_18-35-54 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 5, 5] rbf=[ffourier 5,ffourier 5] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_02-25-00 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 5, 5] rbf=[ffourier 5,ffourier 5] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_09-20-26 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 5, 5] rbf=[ffourier 5,ffourier 5] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_09-47-24 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 5, 5] rbf=[ffourier 5,ffourier 5] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_16-47-47 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier even,fourier even] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_20-41-16 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 5, 5] rbf=[ffourier 5,ffourier 5] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_10-57-02 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier,fourier] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_07-24-55 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd,fourier odd] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_13-10-37 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd lin,fourier odd lin] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_20-50-34 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd lin,fourier odd lin] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_07-05-43 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd sgn,fourier odd sgn] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_20-53-19 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd sgn,fourier odd sgn] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_23-21-54 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 5, 5] rbf=[ffourier 5,ffourier 5] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_01-10-02 seed 398764591\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[ffourier,ffourier] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_10-40-54 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd,fourier odd] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_21-51-21 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier,fourier] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_18-26-38 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[ffourier,ffourier] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_18-39-12 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[dmcf,linear] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_23-24-56 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd,fourier odd] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_04-51-38 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier,fourier] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-22_15-22-14 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier,fourier] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_16-09-48 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier even,fourier even] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_06-35-05 seed 924231285\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[dmcf,linear] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_16-55-44 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd,fourier odd] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_05-30-11 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd,fourier odd] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_09-20-26 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[dmcf,linear] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_09-10-39 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd sgn,fourier odd sgn] map = cartesian window = poly6 d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_23-02-46 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier even,fourier even] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-24_05-41-46 seed 441365315\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd sgn,fourier odd sgn] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-23_16-22-13 seed 404868288\" -d \"~/dev/datasets/generative2D/test\"\n",
      "python ./eval2D.py -i \"./paperData_ablation_fourierTerms/default - n=[ 4, 4] rbf=[fourier odd sgn,fourier odd sgn] map = cartesian window = None d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-21_13-05-56 seed 209652396\" -d \"~/dev/datasets/generative2D/test\"\n"
     ]
    }
   ],
   "source": [
    "inputs = ['./' + s.split('/')[-2] + '/' + s.split('/')[-1] for s in subfolders]\n",
    "data = '~/dev/datasets/generative2D/test'\n",
    "# print(inputs[0])\n",
    "for i in inputs:\n",
    "    print('python ./eval2D.py -i \"%s\" -d \"%s\"' % (i, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ebc089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/winchenbach/servus05/dev/torchSPH2/Cconv/paperData_ablation_windowFunctions/default - n=[ 4, 4] rbf=[rbf linear,rbf linear] map = cartesian window = cubicSpline d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-30_00-52-51 seed 404868288\n"
     ]
    }
   ],
   "source": [
    "print(subfolders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ed52bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = subfolders[0]\n",
    "\n",
    "with open(\"%s/results.json\" % inputFile, \"r\") as read_file:\n",
    "        decodedArray = json.load(read_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5c50fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3033804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c8a1d88b6442889d2b685f27f3bc5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29698d2e227e4d8bbfa564c260911e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(trainingData[it])\n\u001b[1;32m      9\u001b[0m stepLosses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(data, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m dataFrame \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrbf_x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecodedArray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhyperParameters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrbf_x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrbf_y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecodedArray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhyperParameters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrbf_y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m     \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecodedArray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhyperParameters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m     \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecodedArray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhyperParameters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwindow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecodedArray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhyperParameters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwindowFunction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmap\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m   \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecodedArray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhyperParameters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoordinateMapping\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecodedArray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhyperParameters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnetworkSeed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43march\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecodedArray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhyperParameters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43march\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochIteration\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miteration\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirstStepLoss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstepLosses\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlastStepLoss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstepLosses\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmeanLoss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstepLosses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m counter \u001b[38;5;241m=\u001b[39m counter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     27\u001b[0m dataSet \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([dataSet, dataFrame], ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.9/site-packages/pandas/core/frame.py:745\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    744\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 745\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    747\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    748\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    753\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    754\u001b[0m         arrays,\n\u001b[1;32m    755\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    758\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    759\u001b[0m     )\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.9/site-packages/pandas/core/internals/construction.py:511\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    509\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 511\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.9/site-packages/pandas/core/internals/construction.py:876\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    873\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    874\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 876\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.9/site-packages/pandas/core/internals/construction.py:976\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m--> 976\u001b[0m     contents \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_object_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m contents, columns\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.9/site-packages/pandas/core/internals/construction.py:1061\u001b[0m, in \u001b[0;36m_convert_object_array\u001b[0;34m(content, dtype)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         arr \u001b[38;5;241m=\u001b[39m maybe_cast_to_datetime(arr, dtype)\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[0;32m-> 1061\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [convert(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m content]\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.9/site-packages/pandas/core/internals/construction.py:1061\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         arr \u001b[38;5;241m=\u001b[39m maybe_cast_to_datetime(arr, dtype)\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[0;32m-> 1061\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m content]\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.9/site-packages/pandas/core/internals/construction.py:1058\u001b[0m, in \u001b[0;36m_convert_object_array.<locals>.convert\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1057\u001b[0m     arr \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(arr)\n\u001b[0;32m-> 1058\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_cast_to_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1301\u001b[0m, in \u001b[0;36mmaybe_cast_to_datetime\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmaybe_cast_to_datetime\u001b[39m(\n\u001b[1;32m   1293\u001b[0m     value: ExtensionArray \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m, dtype: DtypeObj \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ExtensionArray \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;124;03m    try to cast the array/value to a datetimelike dtype, converting float\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;124;03m    nan to iNaT\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m \n\u001b[1;32m   1299\u001b[0m \u001b[38;5;124;03m    We allow a list *only* when dtype is not None.\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatetimes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sequence_to_datetimes\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtimedeltas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimedeltaArray\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(value):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataSet = pd.DataFrame()\n",
    "counter = 0\n",
    "for epoch in tqdm(decodedArray['epochData']):\n",
    "#     epoch = '025'\n",
    "    trainingData = decodedArray['epochData'][epoch]['training']\n",
    "#     print(len(trainingData))\n",
    "    for it in tqdm(range(len(trainingData)), leave = False):\n",
    "        data = np.array(trainingData[it])\n",
    "        stepLosses = np.mean(data, axis = 1)\n",
    "        dataFrame = pd.DataFrame([{\n",
    "            'rbf_x' : decodedArray['hyperParameters']['rbf_x'], \n",
    "            'rbf_y' : decodedArray['hyperParameters']['rbf_y'], \n",
    "            'n'     : decodedArray['hyperParameters']['n'], \n",
    "            'm'     : decodedArray['hyperParameters']['m'],\n",
    "            'window': decodedArray['hyperParameters']['windowFunction'],\n",
    "            'map'   : decodedArray['hyperParameters']['coordinateMapping'],\n",
    "            'seed'  : decodedArray['hyperParameters']['networkSeed'],\n",
    "            'arch'  : decodedArray['hyperParameters']['arch'],\n",
    "            'epoch' : int(epoch),\n",
    "            'epochIteration' : it,\n",
    "            'iteration': counter + 1,\n",
    "            'firstStepLoss': stepLosses[0],\n",
    "            'lastStepLoss': stepLosses[-1],\n",
    "            'meanLoss': np.mean(stepLosses)\n",
    "                                  }])\n",
    "        counter = counter + 1\n",
    "        dataSet = pd.concat([dataSet, dataFrame], ignore_index = True)\n",
    "#         break\n",
    "#     break\n",
    "# dataFrame.insert\n",
    "# display(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90e179b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/winchenbach/servus05/dev/torchSPH2/Cconv/paperData_ablation_windowFunctions/default - n=[ 4, 4] rbf=[rbf linear,rbf linear] map = cartesian window = cubicSpline d = 16 e = 25 arch 32 64 64 3 distance = 16 - 2023-07-30_00-52-51 seed 404868288 - training.csv\n"
     ]
    }
   ],
   "source": [
    "# print('%s - training.csv' % inputFile)\n",
    "dataSet.to_csv('%s - training.csv' % inputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97ad4fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rbfConv import *\n",
    "from datautils import *\n",
    "from rbfNet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a611aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loadRbfModel(file, frame, networkPath, epoch):\n",
    "    with open(os.path.expanduser(\"%s/results.json\" % networkPath), \"r\") as read_file:\n",
    "        decodedArray = json.load(read_file)\n",
    "        dataDict = decodedArray\n",
    "    \n",
    "    n = dataDict['hyperParameters']['n']\n",
    "    m = dataDict['hyperParameters']['m']\n",
    "    coordinateMapping = dataDict['hyperParameters']['coordinateMapping']\n",
    "    windowFn = getWindowFunction(dataDict['hyperParameters']['windowFunction'])\n",
    "    rbf_x = dataDict['hyperParameters']['rbf_x']\n",
    "    rbf_y = dataDict['hyperParameters']['rbf_y']\n",
    "    dist = dataDict['hyperParameters']['frameDistance']\n",
    "    unroll = dataDict['hyperParameters']['maxRollOut']\n",
    "    arch = [32, 64, 64, 2]\n",
    "    arch = [16, 32, 32, 2]\n",
    "    arch = dataDict['hyperParameters']['arch']\n",
    "    arch = [int(a) for a in arch.split(' ') if a != '']\n",
    "    epochs = dataDict['hyperParameters']['epochs']\n",
    "#     print(arch)\n",
    "#     print(n, m)\n",
    "#     print(dataDict['hyperParameters']['windowFunction'])\n",
    "#     print(rbf_x)\n",
    "#     print(rbf_y)\n",
    "\n",
    "    attributes, inputData, groundTruthData = loadFrame(file, frame, 1 + np.arange(unroll), dist)\n",
    "    inputData['fluidGravity'] = inputData['fluidGravity'][:,:2]\n",
    "    \n",
    "    \n",
    "    fluidPositions, boundaryPositions, fluidFeatures, boundaryFeatures = constructFluidFeatures(attributes, inputData)\n",
    "#     print(fluidFeatures.shape)\n",
    "#     print(boundaryFeatures.shape)\n",
    "    if 'network' not in dataDict['hyperParameters']:\n",
    "        model = RbfNet(fluidFeatures.shape[1],boundaryFeatures.shape[1], layers = arch, coordinateMapping = coordinateMapping, n = n, m = m, windowFn = windowFn, rbf_x = rbf_x, rbf_y = rbf_y, batchSize = 32, )\n",
    "    else:\n",
    "        network = dataDict['hyperParameters']['network']\n",
    "        model = None\n",
    "        if network == 'default':\n",
    "            model = RbfNet(fluidFeatures.shape[1],boundaryFeatures.shape[1], layers = arch, coordinateMapping = coordinateMapping, n = n, m = m, windowFn = windowFn, rbf_x = rbf_x, rbf_y = rbf_y, batchSize = 32, normalized = False )\n",
    "        if network == 'denormalized':\n",
    "            model = RbfNet(fluidFeatures.shape[1],boundaryFeatures.shape[1], layers = arch, coordinateMapping = coordinateMapping, n = n, m = m, windowFn = windowFn, rbf_x = rbf_x, rbf_y = rbf_y, batchSize = 32, normalized = False)\n",
    "        if network == 'split':\n",
    "            model = RbfSplitNet(fluidFeatures.shape[1],boundaryFeatures.shape[1], layers = arch, coordinateMapping = coordinateMapping, n = n, m = m, windowFn = windowFn, rbf_x = rbf_x, rbf_y = rbf_y, batchSize = 32, )\n",
    "        if network == 'interleaved':\n",
    "            model = RbfInterleaveNet(fluidFeatures.shape[1],boundaryFeatures.shape[1], layers = arch, coordinateMapping = coordinateMapping, n = n, m = m, windowFn = windowFn, rbf_x = rbf_x, rbf_y = rbf_y, batchSize = 32, )\n",
    "        if network == 'input':\n",
    "            model = RbfInputNet(fluidFeatures.shape[1],boundaryFeatures.shape[1], layers = arch, coordinateMapping = coordinateMapping, n = n, m = m, windowFn = windowFn, rbf_x = rbf_x, rbf_y = rbf_y, batchSize = 32, )\n",
    "        if network == 'output':\n",
    "            model = RbfOutputNet(fluidFeatures.shape[1],boundaryFeatures.shape[1], layers = arch, coordinateMapping = coordinateMapping, n = n, m = m, windowFn = windowFn, rbf_x = rbf_x, rbf_y = rbf_y, batchSize = 32, )\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.expanduser('%s/model_%03d.torch' % (networkPath, epoch if epoch >= 0 else epochs - 1))))\n",
    "    model = model.to(device)\n",
    "    model.train(False)\n",
    "    return model, dataDict['hyperParameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c535201",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.jit.script\n",
    "def wendland(q, h):\n",
    "    C = 7 / np.pi\n",
    "    b1 = torch.pow(1. - q, 4)\n",
    "    b2 = 1.0 + 4.0 * q\n",
    "    return b1 * b2 * C / h**2    \n",
    "@torch.jit.script\n",
    "def wendlandGrad(q,r,h):\n",
    "    C = 7 / np.pi    \n",
    "    return - r * C / h**3 * (20. * q * (1. -q)**3)[:,None]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9d4fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParticleQuantities(positions, bPositions, area, boundaryArea, attributes):\n",
    "    # bPositions = boundaryPositions.to(device)\n",
    "    # area = inputData['fluidArea'].to(device)\n",
    "    # boundaryArea = inputData['boundaryArea'].to(device)\n",
    "\n",
    "    fi, fj = radius(positions, positions, attributes['support'], max_num_neighbors = 256, batch_x = None, batch_y = None)\n",
    "    bf, bb = radius(bPositions, positions, attributes['support'], max_num_neighbors = 256, batch_x = None, batch_y = None)\n",
    "    bi, bj = radius(bPositions, bPositions, attributes['support'], max_num_neighbors = 256, batch_x = None, batch_y = None)\n",
    "\n",
    "    i, ni = torch.unique(fi, return_counts = True)\n",
    "    b, nb = torch.unique(bf, return_counts = True)\n",
    "\n",
    "    fluidNeighbors = torch.stack([fi, fj], dim = 0)\n",
    "    fluidDistances = (positions[fi] - positions[fj])\n",
    "    fluidRadialDistances = torch.linalg.norm(fluidDistances,axis=1)\n",
    "    fluidDistances[fluidRadialDistances < 1e-5,:] = 0\n",
    "    fluidDistances[fluidRadialDistances >= 1e-5,:] /= fluidRadialDistances[fluidRadialDistances >= 1e-5,None]\n",
    "    fluidRadialDistances /= attributes['support']\n",
    "\n",
    "    boundaryNeighbors = torch.stack([bf, bb], dim = 0)\n",
    "    boundaryDistances = (positions[bf] - bPositions[bb])\n",
    "    boundaryRadialDistances = torch.linalg.norm(boundaryDistances,axis=1)\n",
    "    boundaryDistances[boundaryRadialDistances < 1e-5,:] = 0\n",
    "    boundaryDistances[boundaryRadialDistances >= 1e-5,:] /= boundaryRadialDistances[boundaryRadialDistances >= 1e-5,None]\n",
    "    boundaryRadialDistances /= attributes['support']\n",
    "\n",
    "    boundaryBoundaryNeighbors = torch.stack([bi, bj], dim = 0)\n",
    "    boundaryBoundaryDistances = (bPositions[bi] - bPositions[bj])\n",
    "    boundaryBoundaryRadialDistances = torch.linalg.norm(boundaryBoundaryDistances,axis=1)\n",
    "    boundaryBoundaryDistances[boundaryBoundaryRadialDistances < 1e-5,:] = 0\n",
    "    boundaryBoundaryDistances[boundaryBoundaryRadialDistances >= 1e-5,:] /= boundaryBoundaryRadialDistances[boundaryBoundaryRadialDistances >= 1e-5,None]\n",
    "    boundaryBoundaryRadialDistances /= attributes['support']\n",
    "    density = scatter(area[fj] * wendland(fluidRadialDistances, attributes['support']), fi, dim=0, dim_size = positions.shape[0], reduce='add') + \\\n",
    "        scatter(boundaryArea[bb] * wendland(boundaryRadialDistances, attributes['support']), bf, dim=0, dim_size = positions.shape[0], reduce='add')\n",
    "#     densityLoss = (density - groundTruths[0][:,4].to(device))**2\n",
    "\n",
    "    boundaryDensity = scatter(area[bf] * wendland(boundaryRadialDistances, attributes['support']), bb, dim=0, dim_size = bPositions.shape[0], reduce='add') + \\\n",
    "            scatter(boundaryArea[bj] * wendland(boundaryBoundaryRadialDistances, attributes['support']), bi, dim=0, dim_size = bPositions.shape[0], reduce='add')\n",
    "    # print(boundaryDensity)\n",
    "    colorField = scatter(area[fj]/density[fj] * wendland(fluidRadialDistances, attributes['support']), fi, dim=0, dim_size = positions.shape[0], reduce='add') + \\\n",
    "        scatter(boundaryArea[bb]/boundaryDensity[bb] * wendland(boundaryRadialDistances, attributes['support']), bf, dim=0, dim_size = positions.shape[0], reduce='add')\n",
    "    boundaryColorField = scatter(area[bf]/density[bf] * wendland(boundaryRadialDistances, attributes['support']), bb, dim=0, dim_size = bPositions.shape[0], reduce='add') + \\\n",
    "        scatter(boundaryArea[bi]/boundaryDensity[bi] * wendland(boundaryBoundaryRadialDistances, attributes['support']), bj, dim=0, dim_size = bPositions.shape[0], reduce='add')\n",
    "\n",
    "    fluidGrad = wendlandGrad(fluidRadialDistances, fluidDistances, attributes['support'])\n",
    "    boundaryGrad = wendlandGrad(boundaryRadialDistances, boundaryDistances, attributes['support'])\n",
    "    colorGrad = scatter((area[fj]/density[fj] * (colorField[fj] - colorField[fi]))[:,None] * fluidGrad, fi, dim=0, dim_size = positions.shape[0], reduce='add') + \\\n",
    "            scatter((boundaryArea[bb]/boundaryDensity[bb] * (boundaryColorField[bb] - colorField[bf]))[:,None] * boundaryGrad, bf, dim=0, dim_size = positions.shape[0], reduce='add')\n",
    "\n",
    "    return density, colorField, colorGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9727e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeshQuantities(xFluid, bPositions, area, boundaryArea, density, velocity, attributes, n = 512, supportScale = 1):\n",
    "    x = torch.linspace(-1,1,n, device = xFluid.device, dtype = xFluid.dtype)\n",
    "    y = torch.linspace(-1,1,n, device = xFluid.device, dtype = xFluid.dtype)\n",
    "    xx,yy = torch.meshgrid(x,y, indexing='xy')\n",
    "\n",
    "    xxf = xx.flatten()\n",
    "    yyf = yy.flatten()\n",
    "    positions = torch.vstack((xxf, yyf)).mT\n",
    "    z = yyf\n",
    "    # z = torch.linalg.norm(positions,dim=1).reshape(xx.shape)\n",
    "#     bPositions = boundaryPositions.to(device)\n",
    "#     area = inputData['fluidArea'].to(device)\n",
    "#     boundaryArea = inputData['boundaryArea'].to(device)\n",
    "\n",
    "    xm, xf = radius(xFluid, positions, attributes['support'] * supportScale, max_num_neighbors = 256, batch_x = None, batch_y = None)\n",
    "\n",
    "\n",
    "    # fluidNeighbors = torch.stack([xf, xm], dim = 0)\n",
    "    fluidDistances = (positions[xm] - xFluid[xf])\n",
    "    fluidRadialDistances = torch.linalg.norm(fluidDistances,axis=1)\n",
    "    fluidDistances[fluidRadialDistances < 1e-5,:] = 0\n",
    "    fluidDistances[fluidRadialDistances >= 1e-5,:] /= fluidRadialDistances[fluidRadialDistances >= 1e-5,None]\n",
    "    fluidRadialDistances /= attributes['support'] * supportScale\n",
    "\n",
    "\n",
    "    bm, bb = radius(bPositions, positions, attributes['support'] * supportScale, max_num_neighbors = 256, batch_x = None, batch_y = None)\n",
    "\n",
    "\n",
    "    # fluidNeighbors = torch.stack([xf, xm], dim = 0)\n",
    "    boundaryDistances = (positions[bm] - bPositions[bb])\n",
    "    boundaryRadialDistances = torch.linalg.norm(boundaryDistances,axis=1)\n",
    "    boundaryDistances[boundaryRadialDistances < 1e-5,:] = 0\n",
    "    boundaryDistances[boundaryRadialDistances >= 1e-5,:] /= boundaryRadialDistances[boundaryRadialDistances >= 1e-5,None]\n",
    "    boundaryRadialDistances /= attributes['support'] * supportScale\n",
    "    \n",
    "    meshDensity = scatter(area[xf] * wendland(fluidRadialDistances, attributes['support'] * supportScale), xm, dim=0, dim_size = positions.shape[0], reduce = 'add') + \\\n",
    "    scatter(boundaryArea[bb] * wendland(boundaryRadialDistances, attributes['support'] * supportScale), bm, dim=0, dim_size = positions.shape[0], reduce = 'add')\n",
    "    \n",
    "    meshVelocity = scatter((area[xf] / density[xf] * wendland(fluidRadialDistances, attributes['support'] * supportScale))[:,None] * velocity[xf], xm, dim=0, dim_size = positions.shape[0], reduce = 'add')\n",
    "\n",
    "    meshDivergence = scatter(area[xf] / density[xf] * torch.einsum('nd, nd -> n', (wendlandGrad(fluidRadialDistances, fluidDistances, attributes['support'] * supportScale)), velocity[xf] - meshVelocity[xm]), xm, dim=0, dim_size = positions.shape[0], reduce = 'add')\n",
    "    \n",
    "    return positions.reshape((xx.shape[0],xx.shape[1],2)), meshDensity.reshape((xx.shape[0],xx.shape[1])), meshVelocity.reshape((xx.shape[0],xx.shape[1],2)), meshDivergence.reshape((xx.shape[0],xx.shape[1]))\n",
    "\n",
    "def plotMeshData(fp, meshDensity, gtMeshDensity, meshVelocity, gtMeshVelocity, meshDivergence, gtMeshDivergence):\n",
    "    fig, axis = plt.subplots(3, 5, figsize=(16,12), sharex = False, sharey = False, squeeze = False)\n",
    "    meshPlot(axis[0,0], fp, meshDensity, 'Pred Density')\n",
    "    meshPlot(axis[0,1], fp, meshVelocity[:,:,0], 'Pred Velocity.x')\n",
    "    meshPlot(axis[0,2], fp, meshVelocity[:,:,1], 'Pred Velocity.y')\n",
    "    meshPlot(axis[0,3], fp, torch.linalg.norm(meshVelocity, dim=2), '|Pred Velocity|')\n",
    "    meshPlot(axis[0,4], fp, meshDivergence, 'Pred Divergence')\n",
    "\n",
    "    meshPlot(axis[1,0], fp, gtMeshDensity, 'GT Density')\n",
    "    meshPlot(axis[1,1], fp, gtMeshVelocity[:,:,0], 'GT Velocity.x')\n",
    "    meshPlot(axis[1,2], fp, gtMeshVelocity[:,:,1], 'GT Velocity.y')\n",
    "    meshPlot(axis[1,3], fp, torch.linalg.norm(gtMeshVelocity, dim=2), '|GT Velocity|')\n",
    "    meshPlot(axis[1,4], fp, gtMeshDivergence, 'GT Divergence')\n",
    "\n",
    "    meshPlot(axis[2,0], fp, meshDensity - gtMeshDensity, 'Diff Density')\n",
    "    meshPlot(axis[2,1], fp, meshVelocity[:,:,0] - gtMeshVelocity[:,:,0], 'Diff Velocity.x')\n",
    "    meshPlot(axis[2,2], fp, meshVelocity[:,:,1] - gtMeshVelocity[:,:,1], 'Diff Velocity.y')\n",
    "    meshPlot(axis[2,3], fp, torch.linalg.norm(meshVelocity - gtMeshVelocity, dim=2), '|Diff Velocity|')\n",
    "    meshPlot(axis[2,4], fp, meshDivergence - gtMeshDivergence, 'Diff Divergence')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "\n",
    "def meshPlot(ax, positions, data, title = None):\n",
    "    ax.axis('equal')\n",
    "#     print(positions[:,:,0].flatten().shape)\n",
    "#     print(data.shape)\n",
    "    im = ax.pcolormesh(positions[:,:,0].detach().cpu().numpy(), positions[:,:,1].detach().cpu().numpy(), data.detach().cpu().numpy())    \n",
    "#     ax.scatter(boundaryPositions[:,0], boundaryPositions[:,1], s=1,c='white',alpha=0.5)\n",
    "    ax.set_xlim(-1.,1.)\n",
    "    ax.set_ylim(-1.,1.)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax1_divider = make_axes_locatable(ax)\n",
    "    cax1 = ax1_divider.append_axes(\"bottom\", size=\"7%\", pad=\"2%\")\n",
    "    GTcbar = fig.colorbar(im, cax=cax1,orientation='horizontal')\n",
    "    GTcbar.ax.tick_params(labelsize=8) \n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    return im, GTcbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e482391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeParticles(positions, gtPositions, boundaryPositions, velocities, gtVelocities, fluidArea, boundaryArea, attributes):    \n",
    "    positionLoss = torch.linalg.norm(positions - gtPositions.to(device), dim=1)\n",
    "    velocityLoss = torch.linalg.norm(velocities - gtVelocities.to(device), dim=1)\n",
    "    density, colorField, colorGrad = getParticleQuantities(positions, boundaryPositions, fluidArea, boundaryArea, attributes)\n",
    "    \n",
    "    gTPositionLoss = torch.linalg.norm(gtPositions - gtPositions, dim=1)\n",
    "    gtVelocityLoss = torch.linalg.norm(gtVelocities - gtVelocities, dim=1)\n",
    "    gtDensity2, gtColorField, gtColorGrad = getParticleQuantities(gtPositions, boundaryPositions, fluidArea, boundaryArea, attributes)\n",
    "    \n",
    "    return positionLoss, velocityLoss, density, gtDensity2, colorField, gtColorField, colorGrad, gtColorGrad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1298c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particleAnalysis(positions, gtPositions, boundaryPositions, velocities, gtVelocities, fluidArea, boundaryArea, attributes, plot = True):\n",
    "    positionLoss, velocityLoss, density, gtDensity, colorField, gtColorField, colorGrad, gtColorGrad = analyzeParticles(positions, gtPositions, boundaryPositions, velocities, gtVelocities, fluidArea, boundaryArea, attributes)\n",
    "    if plot:\n",
    "        fig, axis = plt.subplots(3, 6, figsize=(12,8*1.09), sharex = False, sharey = False, squeeze = False)\n",
    "\n",
    "        scatterPlot(axis[0,0], positions, positionLoss, boundaryPositions, 'Position Loss')\n",
    "        scatterPlot(axis[0,1], positions, velocityLoss, boundaryPositions, 'Velocity Loss')\n",
    "        scatterPlot(axis[0,2], positions, density, boundaryPositions, 'Density')\n",
    "        scatterPlot(axis[0,3], positions, colorField, boundaryPositions, 'Color')\n",
    "        scatterPlot(axis[0,4], positions, colorGrad[:,0], boundaryPositions, 'Grad.x Color')\n",
    "        scatterPlot(axis[0,5], positions, colorGrad[:,1], boundaryPositions, 'Grad.y Color')\n",
    "\n",
    "        scatterPlot(axis[1,0], gtPositions, torch.zeros_like(density), boundaryPositions, 'GT Position Loss')\n",
    "        scatterPlot(axis[1,1], gtPositions, torch.zeros_like(density), boundaryPositions, 'GT Velocity Loss')\n",
    "        scatterPlot(axis[1,2], gtPositions, gtDensity, boundaryPositions, 'GT Density')\n",
    "        scatterPlot(axis[1,3], gtPositions, gtColorField, boundaryPositions, 'GT Color')\n",
    "        scatterPlot(axis[1,4], gtPositions, gtColorGrad[:,0], boundaryPositions, 'GT Grad.x Color')\n",
    "        scatterPlot(axis[1,5], gtPositions, gtColorGrad[:,1], boundaryPositions, 'GT Grad.y Color')\n",
    "\n",
    "        scatterPlot(axis[2,0], gtPositions, positionLoss, boundaryPositions, 'Position Loss')\n",
    "        scatterPlot(axis[2,1], gtPositions, velocityLoss, boundaryPositions, 'Velocity Loss')\n",
    "        scatterPlot(axis[2,2], gtPositions, density - gtDensity, boundaryPositions, 'Diff Density')\n",
    "        scatterPlot(axis[2,3], gtPositions, colorField - gtColorField, boundaryPositions, 'Diff Color')\n",
    "        scatterPlot(axis[2,4], gtPositions, colorGrad[:,0] - gtColorGrad[:,0], boundaryPositions, 'Diff Grad.x Color')\n",
    "        scatterPlot(axis[2,5], gtPositions, colorGrad[:,1] - gtColorGrad[:,1], boundaryPositions, 'Diff Grad.y Color')\n",
    "\n",
    "        fig.tight_layout()\n",
    "    return positionLoss, velocityLoss, density, gtDensity, colorField, gtColorField, colorGrad, gtColorGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50a2e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def getPSD(data):\n",
    "    image = data.detach().cpu().numpy()\n",
    "    npix = image.shape[0]\n",
    "    fourier_image = np.fft.fftn(image)\n",
    "    fourier_amplitudes = np.abs(fourier_image)**2\n",
    "    kfreq = np.fft.fftfreq(npix) * npix\n",
    "\n",
    "    kfreq2D = np.meshgrid(kfreq, kfreq)\n",
    "    knrm = np.sqrt(kfreq2D[0]**2 + kfreq2D[1]**2)\n",
    "    knrm = knrm.flatten()\n",
    "    fourier_amplitudes = fourier_amplitudes.flatten()\n",
    "    kbins = np.arange(0.01, npix//(2*np.pi)+1, 0.5)\n",
    "    kbins = np.arange(0.5, npix//2+1, 1.)\n",
    "\n",
    "    kvals = 0.5 * (kbins[1:] + kbins[:-1])\n",
    "\n",
    "    Abins, _, _ = stats.binned_statistic(knrm, fourier_amplitudes,\n",
    "                                         statistic = \"mean\",\n",
    "                                         bins = kbins)\n",
    "\n",
    "    Abins *= np.pi * (kbins[1:]**2 - kbins[:-1]**2)\n",
    "    return kvals, Abins\n",
    "\n",
    "def analyzeMesh(data, filterLevels = 0):\n",
    "# data = torch.linalg.norm(meshVelocity,dim=1).reshape(xx.shape)\n",
    "    if filterLevels > 0 :\n",
    "        filtered = scipy.ndimage.gaussian_filter(data.detach().cpu().numpy(),filterLevels)\n",
    "        filtered = torch.tensor(filtered, device = data.device, dtype = data.dtype)\n",
    "    else:\n",
    "        filtered = data\n",
    "    # data = torch.linalg.norm(meshVelocity,dim=1)\n",
    "    fft = torch.fft.fftshift(torch.fft.fft2(filtered))\n",
    "    # fft = torch.fft.fft2(torch.linalg.norm(meshVelocity,dim=1).reshape(xx.shape))\n",
    "    fftfreq = torch.fft.fftshift(torch.fft.fftfreq(filtered.shape[0],2 / filtered.shape[0]))\n",
    "    # fftfreq = (torch.fft.fftfreq(xx.shape[0],2 / xx.shape[0]))\n",
    "    fx, ft = torch.meshgrid(fftfreq, fftfreq, indexing = 'xy')\n",
    "    # print(fx.shape)\n",
    "    # print(ft.shape)\n",
    "    fp = torch.vstack((fx.flatten(),ft.flatten())).mT\n",
    "\n",
    "    return fp, fft, getPSD(filtered), filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "752877ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meshAnalysis(positions, data, gtData,plot = True, linThresh = 1e-2, linScale = 1):\n",
    "    fp, fft, psd, filtered = analyzeMesh(data)\n",
    "    fp, gtFft, gtPsd, gtFiltered = analyzeMesh(gtData)\n",
    "    if plot:\n",
    "        fig, axis = plt.subplots(3, 4, figsize=(16,11*1.09), sharex = False, sharey = False, squeeze = False)\n",
    "        meshPlot(axis[0,0], positions, data, 'Original Prediction')\n",
    "        meshPlot(axis[0,1], positions, filtered, 'Filtered Prediction')\n",
    "        ax = axis[0,2]\n",
    "        ax.axis('equal')\n",
    "        ax.set_title('FFT Prediction')\n",
    "        im = ax.pcolormesh(fp[:,0].reshape(data.shape).detach().cpu().numpy(), fp[:,1].reshape(data.shape).detach().cpu().numpy(), torch.real(fft).reshape(data.shape).detach().cpu().numpy(),\n",
    "                          norm=colors.SymLogNorm(linthresh=1, linscale=1, vmin=-torch.max(torch.abs(torch.real(fft))), vmax=torch.max(torch.abs(torch.real(fft))), base=10), cmap = 'twilight')    \n",
    "        ax.set_xscale('symlog', linthresh=linThresh, linscale = linScale, subs = [1, 2, 3, 4, 5, 6, 7, 8, 9])  \n",
    "        ax.set_yscale('symlog', linthresh=linThresh, linscale = linScale, subs = [1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "        ax1_divider = make_axes_locatable(ax)\n",
    "        cax1 = ax1_divider.append_axes(\"bottom\", size=\"5%\", pad=\"15%\")\n",
    "        GTcbar = fig.colorbar(im, cax=cax1,orientation='horizontal')\n",
    "        GTcbar.ax.tick_params(labelsize=8) \n",
    "        kvals,Abins = psd\n",
    "        axis[0,3].set_title('PSD Prediction')\n",
    "        axis[0,3].loglog(kvals, Abins)\n",
    "        axis[0,3].set_xlabel(\"$k$\")\n",
    "        axis[0,3].set_ylabel(\"$P(k)$\")\n",
    "        # axis[0,0].legend()\n",
    "\n",
    "        meshPlot(axis[1,0], positions, gtData, 'Original Groundtruth')\n",
    "        meshPlot(axis[1,1], positions, gtFiltered, 'Filtered Groundtruth')\n",
    "        ax = axis[1,2]\n",
    "        ax.axis('equal')\n",
    "        ax.set_title('FFT Groundtruth')\n",
    "        im = ax.pcolormesh(fp[:,0].reshape(data.shape).detach().cpu().numpy(), fp[:,1].reshape(data.shape).detach().cpu().numpy(), torch.real(gtFft).reshape(data.shape).detach().cpu().numpy(),\n",
    "                          norm=colors.SymLogNorm(linthresh=1, linscale=1, vmin=-torch.max(torch.abs(torch.real(gtFft))), vmax=torch.max(torch.abs(torch.real(gtFft))), base=10), cmap = 'twilight')     \n",
    "        ax.set_xscale('symlog', linthresh=linThresh, linscale = linScale, subs = [1, 2, 3, 4, 5, 6, 7, 8, 9])  \n",
    "        ax.set_yscale('symlog', linthresh=linThresh, linscale = linScale, subs = [1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "        ax1_divider = make_axes_locatable(ax)\n",
    "        cax1 = ax1_divider.append_axes(\"bottom\", size=\"5%\", pad=\"15%\")\n",
    "        GTcbar = fig.colorbar(im, cax=cax1,orientation='horizontal')\n",
    "        GTcbar.ax.tick_params(labelsize=8) \n",
    "        kvals,Abins = gtPsd\n",
    "        axis[1,3].set_title('PSD Groundtruth')\n",
    "        axis[1,3].loglog(kvals, Abins)\n",
    "        axis[1,3].set_xlabel(\"$k$\")\n",
    "        axis[1,3].set_ylabel(\"$P(k)$\")\n",
    "\n",
    "        meshPlot(axis[2,0], positions, data - gtData, 'Original Difference')\n",
    "        meshPlot(axis[2,1], positions, filtered - gtFiltered, 'Filtered Difference')\n",
    "        ax = axis[2,2]\n",
    "        ax.axis('equal')\n",
    "        ax.set_title('FFT Difference')\n",
    "        diff = (torch.real(fft) - torch.real(gtFft))\n",
    "        im = ax.pcolormesh(fp[:,0].reshape(data.shape).detach().cpu().numpy(), fp[:,1].reshape(data.shape).detach().cpu().numpy(), diff.reshape(data.shape).detach().cpu().numpy(),\n",
    "                          norm=colors.SymLogNorm(linthresh=1, linscale=1, vmin=-torch.max(torch.abs(diff)), vmax=torch.max(torch.abs(diff)), base=10), cmap = 'twilight')     \n",
    "        ax.set_xscale('symlog', linthresh=linThresh, linscale = linScale, subs = [1, 2, 3, 4, 5, 6, 7, 8, 9])  \n",
    "        ax.set_yscale('symlog', linthresh=linThresh, linscale = linScale, subs = [1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "        ax1_divider = make_axes_locatable(ax)\n",
    "        cax1 = ax1_divider.append_axes(\"bottom\", size=\"5%\", pad=\"15%\")\n",
    "        GTcbar = fig.colorbar(im, cax=cax1,orientation='horizontal')\n",
    "        GTcbar.ax.tick_params(labelsize=8) \n",
    "        kvals,Abins = gtPsd\n",
    "        axis[2,3].set_title('PSD')\n",
    "        axis[2,3].loglog(kvals, Abins,label = 'GT')\n",
    "        kvals,Abins = psd\n",
    "        axis[2,3].loglog(kvals, Abins,label = 'pred')\n",
    "        axis[2,3].set_xlabel(\"$k$\")\n",
    "        axis[2,3].set_ylabel(\"$P(k)$\")\n",
    "        axis[2,3].legend()\n",
    "\n",
    "        fig.tight_layout()\n",
    "    \n",
    "    return fp, fft, gtFft, psd, gtPsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d3c1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLosses(positions, velocities, gtPositions, gtDensity, gtVelocities, fluidArea, boundaryPositions, boundaryArea, attributes):\n",
    "    positionLoss, velocityLoss, density, gtDensity, colorField, gtColorField, colorGrad, gtColorGrad = particleAnalysis(positions, gtPositions, boundaryPositions, velocities, gtVelocities, fluidArea, boundaryArea, attributes, plot = False)\n",
    "    fp, meshDensity, meshVelocity, meshDivergence = getMeshQuantities(positions, boundaryPositions, fluidArea, boundaryArea, density, velocities, attributes, n = 512)\n",
    "    fp, gtMeshDensity, gtMeshVelocity, gtMeshDivergence = getMeshQuantities(gtPositions, boundaryPositions, fluidArea, boundaryArea, gtDensity, gtVelocities, attributes, n = 512)\n",
    "    # plotMeshData(fp, meshDensity, gtMeshDensity, meshVelocity, gtMeshVelocity, meshDivergence, gtMeshDivergence)\n",
    "\n",
    "    data = torch.linalg.norm(meshVelocity,dim=2)\n",
    "    gtData = torch.linalg.norm(gtMeshVelocity,dim=2)\n",
    "    ffp, fft, gtFft, psd, gtPsd = meshAnalysis(fp, data, gtData,linThresh=1e0, linScale = 0.5, plot = False)\n",
    "    kvals,Abins = psd\n",
    "    kvals,gtAbins = gtPsd\n",
    "\n",
    "    positionLossTerm = torch.mean(positionLoss)\n",
    "    velocityLossTerm = torch.mean(velocityLoss)\n",
    "    densityLossTerm = torch.mean(torch.abs(density - gtDensity))\n",
    "    colorFieldLossTerm = torch.mean(torch.abs(colorField - gtColorField))\n",
    "    colorGradLossTerm = torch.mean(torch.linalg.norm(colorGrad - gtColorGrad,dim=1))\n",
    "\n",
    "    meshDensityLossTerm = torch.mean(torch.abs(meshDensity - gtMeshDensity))\n",
    "    meshVelocityLossTerm = torch.mean(torch.abs(meshVelocity - gtMeshVelocity))\n",
    "    meshDivergenceLossTerm = torch.mean(torch.abs(meshDivergence - gtMeshDivergence))\n",
    "\n",
    "    psdLossTerm = np.sum(np.abs(np.log10(Abins) - np.log10(gtAbins)))\n",
    "    \n",
    "    return {\\\n",
    "            'position': positionLossTerm.item(), \n",
    "            'velocity': velocityLossTerm.item(), \n",
    "            'density': densityLossTerm.item(), \n",
    "            'color': colorFieldLossTerm.item(), \n",
    "            'colorGrad': colorGradLossTerm.item(), \n",
    "            'meshDensity': meshDensityLossTerm.item(), \n",
    "            'meshVelocity': meshVelocityLossTerm.item(), \n",
    "            'meshDivergence': meshDivergenceLossTerm.item(), \n",
    "            'psd': psdLossTerm.item(), \n",
    "            'kvals': kvals, \n",
    "            'Abins': Abins, \n",
    "            'gtAbins':gtAbins}\n",
    "# lossDict = getLosses(positions, velocities, gtPositions, gtDensity, fluidArea, boundaryPositions, boundaryArea, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9bfb5bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loadFrame(filename, frame, frameOffsets = [1], frameDistance = 1, adjustForFrameDistance = True):\n",
    "    if 'zst' in filename:\n",
    "        return loadFrameZSTD(filename, frame, frameOffsets, frameDistance)\n",
    "    inFile = h5py.File(filename)\n",
    "    inGrp = inFile['simulationExport']['%05d' % frame]\n",
    "#     debugPrint(inFile.attrs.keys())\n",
    "    attributes = {\n",
    "     'support': np.max(inGrp['fluidSupport'][:]),\n",
    "     'targetNeighbors': inFile.attrs['targetNeighbors'],\n",
    "     'restDensity': inFile.attrs['restDensity'],\n",
    "     'dt': inGrp.attrs['dt'],\n",
    "     'time': inGrp.attrs['time'],\n",
    "     'radius': inFile.attrs['radius'],\n",
    "     'area': inFile.attrs['radius'] **2 * np.pi,\n",
    "    }\n",
    "#     debugPrint(inGrp.attrs['timestep'])\n",
    "\n",
    "    # support = inFile.attrs['support']\n",
    "    # targetNeighbors = inFile.attrs['targetNeighbors']\n",
    "    # restDensity = inFile.attrs['restDensity']\n",
    "    # dt = inFile.attrs['initialDt']\n",
    "\n",
    "    inputData = {\n",
    "        'fluidPosition': torch.from_numpy(inGrp['fluidPosition'][:]).type(torch.float32),\n",
    "        'fluidVelocity': torch.from_numpy(inGrp['fluidVelocity'][:]).type(torch.float32),\n",
    "        'fluidArea' : torch.from_numpy(inGrp['fluidArea'][:]).type(torch.float32),\n",
    "        'fluidDensity' : torch.from_numpy(inGrp['fluidDensity'][:]).type(torch.float32),\n",
    "        'fluidSupport' : torch.from_numpy(inGrp['fluidSupport'][:]).type(torch.float32),\n",
    "        'fluidGravity' : torch.from_numpy(inGrp['fluidGravity'][:]).type(torch.float32) if 'fluidGravity' not in inFile.attrs else torch.from_numpy(inFile.attrs['fluidGravity']).type(torch.float32) * torch.ones(inGrp['fluidDensity'][:].shape[0])[:,None],\n",
    "        'boundaryPosition': torch.from_numpy(inFile['boundaryInformation']['boundaryPosition'][:]).type(torch.float32),\n",
    "        'boundaryNormal': torch.from_numpy(inFile['boundaryInformation']['boundaryNormals'][:]).type(torch.float32),\n",
    "        'boundaryArea': torch.from_numpy(inFile['boundaryInformation']['boundaryArea'][:]).type(torch.float32),\n",
    "        'boundaryVelocity': torch.from_numpy(inFile['boundaryInformation']['boundaryVelocity'][:]).type(torch.float32),\n",
    "        'boundaryDensity': torch.from_numpy(inGrp['boundaryDensity'][:]).type(torch.float32)\n",
    "    }\n",
    "    if adjustForFrameDistance:\n",
    "        if frame >= frameDistance:\n",
    "            priorGrp = inFile['simulationExport']['%05d' % (frame - frameDistance)]\n",
    "            priorPosition = torch.from_numpy(priorGrp['fluidPosition'][:]).type(torch.float32)\n",
    "            inputData['fluidVelocity'] = (inputData['fluidPosition'] - priorPosition) / (frameDistance * attributes['dt'])\n",
    "            # priorVelocity = torch.from_numpy(priorGrp['fluidVelocity'][:]).type(torch.float32)\n",
    "\n",
    "    groundTruthData = []\n",
    "    for i in frameOffsets:\n",
    "        gtGrp = inFile['simulationExport']['%05d' % (frame + i * frameDistance)]\n",
    "#         debugPrint((frame + i * frameDistance))\n",
    "#         debugPrint(gtGrp.attrs['timestep'])\n",
    "        gtData = {\n",
    "            'fluidPosition'    : torch.from_numpy(gtGrp['fluidPosition'][:]).type(torch.float32),\n",
    "            'fluidVelocity'    : torch.from_numpy(gtGrp['fluidVelocity'][:]).type(torch.float32),\n",
    "            'fluidDensity'     : torch.from_numpy(gtGrp['fluidDensity'][:]).type(torch.float32),\n",
    "    #         'fluidPressure'    : torch.from_numpy(gtGrp['fluidPressure'][:]),\n",
    "    #         'boundaryDensity'  : torch.from_numpy(gtGrp['fluidDensity'][:]),\n",
    "    #         'boundaryPressure' : torch.from_numpy(gtGrp['fluidPressure'][:]),\n",
    "        }\n",
    "        \n",
    "        groundTruthData.append(torch.hstack((gtData['fluidPosition'].type(torch.float32), gtData['fluidVelocity'], gtData['fluidDensity'][:,None])))\n",
    "        \n",
    "    \n",
    "    inFile.close()\n",
    "    \n",
    "    return attributes, inputData, groundTruthData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0381af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b60b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, hyperParams = loadRbfModel(simulationFiles[0], 0, inputFile, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cba19c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unrollSteps = 64\n",
    "\n",
    "\n",
    "simulationIndex = 0\n",
    "initialFrame = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2284b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUnrollFrame(simulationIndex, initialFrame, unrollSteps):\n",
    "    attributes, inputData, groundTruths = loadFrame(simulationFiles[simulationIndex], initialFrame, 1 + np.arange(unrollSteps), hyperParams['frameDistance'], adjustForFrameDistance = False)\n",
    "    fluidPositions, boundaryPositions, fluidFeatures, boundaryFeatures = constructFluidFeatures(attributes, inputData)\n",
    "    fluidFeatures = fluidFeatures.to(device)\n",
    "    # model, hyperParams = loadRbfModel(simulationFiles[0], 0, subfolders[networkIndex], -1)\n",
    "    predictedPositions = fluidPositions.to(device)\n",
    "    predictedVelocity = inputData['fluidVelocity'].to(device)\n",
    "    gravity = inputData['fluidGravity'][:,:2].to(device) \n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for unrollStep in tqdm(range(unrollSteps), leave = False):\n",
    "            _, _, groundTruths2 = loadFrame(simulationFiles[simulationIndex], initialFrame + unrollStep * hyperParams['frameDistance'], 1 + np.arange(hyperParams['frameDistance']), 1)\n",
    "            loss, predictedPositions, predictedVelocity = runNetwork(predictedPositions, predictedVelocity, attributes, hyperParams['frameDistance'], gravity, fluidFeatures, boundaryPositions.to(device), boundaryFeatures.to(device), groundTruths[unrollStep], model, None, None, True)    \n",
    "            positions = predictedPositions\n",
    "            velocities = predictedVelocity\n",
    "            gtPositions = groundTruths[unrollStep][:,:2].to(device)\n",
    "            gtVelocity = torch.vstack([g[:,2:4][None,:] for g in groundTruths2])\n",
    "            gtVelocities = torch.mean(gtVelocity, axis = 0).to(device)\n",
    "\n",
    "            gtVelocities = groundTruths[unrollStep][:,2:4].to(device)\n",
    "            gtDensity = groundTruths[unrollStep][:,4].to(device)\n",
    "            fluidArea = inputData['fluidArea'].to(device)\n",
    "            boundaryPositions = inputData['boundaryPosition'].to(device)\n",
    "            boundaryArea = inputData['boundaryArea'].to(device)\n",
    "\n",
    "            lossDict = getLosses(positions, velocities, gtPositions, gtDensity, gtVelocities, fluidArea, boundaryPositions, boundaryArea, attributes)\n",
    "            losses.append(lossDict)\n",
    "\n",
    "    unrollDict = pd.DataFrame()\n",
    "    for il, l in enumerate(losses):\n",
    "    #     print(l)\n",
    "        dataFrame = pd.DataFrame([{\n",
    "            'rbf_x' : decodedArray['hyperParameters']['rbf_x'], \n",
    "            'rbf_y' : decodedArray['hyperParameters']['rbf_y'], \n",
    "            'n'     : decodedArray['hyperParameters']['n'], \n",
    "            'm'     : decodedArray['hyperParameters']['m'],\n",
    "            'window': decodedArray['hyperParameters']['windowFunction'],\n",
    "            'map'   : decodedArray['hyperParameters']['coordinateMapping'],\n",
    "            'seed'  : decodedArray['hyperParameters']['networkSeed'],\n",
    "            'arch'  : decodedArray['hyperParameters']['arch'],\n",
    "            'testFile': simulationFiles[simulationIndex].split('.')[0].split(' ')[-1],\n",
    "            'initialFrame': initialFrame,\n",
    "            'unrollStep': il,\n",
    "            'positionError': l['position'],\n",
    "            'velocityError': l['velocity'],\n",
    "            'densityError': l['density'],\n",
    "            'colorError': l['color'],\n",
    "            'colorGradError': l['colorGrad'],\n",
    "            'meshDensityError': l['meshDensity'],\n",
    "            'meshVelocityError': l['meshVelocity'],\n",
    "            'meshDivergenceError': l['meshDivergence'],\n",
    "            'psdError': l['psd'],\n",
    "                                  }])\n",
    "        unrollDict = pd.concat([unrollDict, dataFrame], ignore_index = True)\n",
    "    #     display(dataFrame)\n",
    "    #     break\n",
    "#     display(unrollDict)\n",
    "    return unrollDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5de4e0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [97]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m simulationIndex \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m]:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m initialFrame \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m2175\u001b[39m]:\n\u001b[0;32m----> 4\u001b[0m         unrollDict \u001b[38;5;241m=\u001b[39m \u001b[43mgetUnrollFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulationIndex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitialFrame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m         overallDict \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([overallDict, unrollDict], ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36mgetUnrollFrame\u001b[0;34m(simulationIndex, initialFrame, unrollSteps)\u001b[0m\n\u001b[1;32m     23\u001b[0m         boundaryPositions \u001b[38;5;241m=\u001b[39m inputData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboundaryPosition\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     24\u001b[0m         boundaryArea \u001b[38;5;241m=\u001b[39m inputData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboundaryArea\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 26\u001b[0m         lossDict \u001b[38;5;241m=\u001b[39m \u001b[43mgetLosses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvelocities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtPositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtDensity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtVelocities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfluidArea\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundaryPositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundaryArea\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m         losses\u001b[38;5;241m.\u001b[39mappend(lossDict)\n\u001b[1;32m     29\u001b[0m unrollDict \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36mgetLosses\u001b[0;34m(positions, velocities, gtPositions, gtDensity, gtVelocities, fluidArea, boundaryPositions, boundaryArea, attributes)\u001b[0m\n\u001b[1;32m      2\u001b[0m positionLoss, velocityLoss, density, gtDensity, colorField, gtColorField, colorGrad, gtColorGrad \u001b[38;5;241m=\u001b[39m particleAnalysis(positions, gtPositions, boundaryPositions, velocities, gtVelocities, fluidArea, boundaryArea, attributes, plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m fp, meshDensity, meshVelocity, meshDivergence \u001b[38;5;241m=\u001b[39m getMeshQuantities(positions, boundaryPositions, fluidArea, boundaryArea, density, velocities, attributes, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m fp, gtMeshDensity, gtMeshVelocity, gtMeshDivergence \u001b[38;5;241m=\u001b[39m \u001b[43mgetMeshQuantities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgtPositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundaryPositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfluidArea\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundaryArea\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtDensity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtVelocities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# plotMeshData(fp, meshDensity, gtMeshDensity, meshVelocity, gtMeshVelocity, meshDivergence, gtMeshDivergence)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(meshVelocity,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36mgetMeshQuantities\u001b[0;34m(xFluid, bPositions, area, boundaryArea, density, velocity, attributes, n, supportScale)\u001b[0m\n\u001b[1;32m      9\u001b[0m     z \u001b[38;5;241m=\u001b[39m yyf\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# z = torch.linalg.norm(positions,dim=1).reshape(xx.shape)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     bPositions = boundaryPositions.to(device)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#     area = inputData['fluidArea'].to(device)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#     boundaryArea = inputData['boundaryArea'].to(device)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     xm, xf \u001b[38;5;241m=\u001b[39m \u001b[43mradius\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxFluid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msupport\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msupportScale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_neighbors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# fluidNeighbors = torch.stack([xf, xm], dim = 0)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     fluidDistances \u001b[38;5;241m=\u001b[39m (positions[xm] \u001b[38;5;241m-\u001b[39m xFluid[xf])\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.9/site-packages/torch_geometric/nn/pool/__init__.py:171\u001b[0m, in \u001b[0;36mradius\u001b[0;34m(x, y, r, batch_x, batch_y, max_num_neighbors, num_workers)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mradius\u001b[39m(x: Tensor, y: Tensor, r: \u001b[38;5;28mfloat\u001b[39m, batch_x: OptTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    135\u001b[0m            batch_y: OptTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, max_num_neighbors: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m    136\u001b[0m            num_workers: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Finds for each element in :obj:`y` all points in :obj:`x` within\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    distance :obj:`r`.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m        assign_index = radius(x, y, 1.5, batch_x, batch_y)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_cluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "overallDict = pd.DataFrame()\n",
    "for simulationIndex in [0,1,2,4]:\n",
    "    for initialFrame in [0, 512, 1024, 2175]:\n",
    "        unrollDict = getUnrollFrame(simulationIndex, initialFrame, 64)\n",
    "        overallDict = pd.concat([overallDict, unrollDict], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5e76e4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rbf_x</th>\n",
       "      <th>rbf_y</th>\n",
       "      <th>n</th>\n",
       "      <th>m</th>\n",
       "      <th>window</th>\n",
       "      <th>map</th>\n",
       "      <th>seed</th>\n",
       "      <th>arch</th>\n",
       "      <th>testFile</th>\n",
       "      <th>initialFrame</th>\n",
       "      <th>unrollStep</th>\n",
       "      <th>positionError</th>\n",
       "      <th>velocityError</th>\n",
       "      <th>densityError</th>\n",
       "      <th>colorError</th>\n",
       "      <th>colorGradError</th>\n",
       "      <th>meshDensityError</th>\n",
       "      <th>meshVelocityError</th>\n",
       "      <th>meshDivergenceError</th>\n",
       "      <th>psdError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf linear</td>\n",
       "      <td>rbf linear</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>cubicSpline</td>\n",
       "      <td>cartesian</td>\n",
       "      <td>404868288</td>\n",
       "      <td>32 64 64 3</td>\n",
       "      <td>2023-03-13_10-01-01</td>\n",
       "      <td>2175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.042205</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.262954</td>\n",
       "      <td>4.089778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rbf linear</td>\n",
       "      <td>rbf linear</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>cubicSpline</td>\n",
       "      <td>cartesian</td>\n",
       "      <td>404868288</td>\n",
       "      <td>32 64 64 3</td>\n",
       "      <td>2023-03-13_10-01-01</td>\n",
       "      <td>2175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.025437</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.026141</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.278887</td>\n",
       "      <td>10.122508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rbf linear</td>\n",
       "      <td>rbf linear</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>cubicSpline</td>\n",
       "      <td>cartesian</td>\n",
       "      <td>404868288</td>\n",
       "      <td>32 64 64 3</td>\n",
       "      <td>2023-03-13_10-01-01</td>\n",
       "      <td>2175</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.029439</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>0.005697</td>\n",
       "      <td>0.010492</td>\n",
       "      <td>0.329314</td>\n",
       "      <td>12.677175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rbf linear</td>\n",
       "      <td>rbf linear</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>cubicSpline</td>\n",
       "      <td>cartesian</td>\n",
       "      <td>404868288</td>\n",
       "      <td>32 64 64 3</td>\n",
       "      <td>2023-03-13_10-01-01</td>\n",
       "      <td>2175</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.037243</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.043079</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.484648</td>\n",
       "      <td>16.561736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rbf linear</td>\n",
       "      <td>rbf linear</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>cubicSpline</td>\n",
       "      <td>cartesian</td>\n",
       "      <td>404868288</td>\n",
       "      <td>32 64 64 3</td>\n",
       "      <td>2023-03-13_10-01-01</td>\n",
       "      <td>2175</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.047529</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>0.070483</td>\n",
       "      <td>0.008582</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.688050</td>\n",
       "      <td>19.844995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>rbf linear</td>\n",
       "      <td>rbf linear</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>cubicSpline</td>\n",
       "      <td>cartesian</td>\n",
       "      <td>404868288</td>\n",
       "      <td>32 64 64 3</td>\n",
       "      <td>2023-03-13_10-01-01</td>\n",
       "      <td>2175</td>\n",
       "      <td>59</td>\n",
       "      <td>0.101666</td>\n",
       "      <td>0.336229</td>\n",
       "      <td>0.042118</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.367478</td>\n",
       "      <td>0.044606</td>\n",
       "      <td>0.147141</td>\n",
       "      <td>4.626566</td>\n",
       "      <td>79.619426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>rbf linear</td>\n",
       "      <td>rbf linear</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>cubicSpline</td>\n",
       "      <td>cartesian</td>\n",
       "      <td>404868288</td>\n",
       "      <td>32 64 64 3</td>\n",
       "      <td>2023-03-13_10-01-01</td>\n",
       "      <td>2175</td>\n",
       "      <td>60</td>\n",
       "      <td>0.104504</td>\n",
       "      <td>0.335782</td>\n",
       "      <td>0.041951</td>\n",
       "      <td>0.015280</td>\n",
       "      <td>0.382724</td>\n",
       "      <td>0.044812</td>\n",
       "      <td>0.147635</td>\n",
       "      <td>4.628899</td>\n",
       "      <td>69.533739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>rbf linear</td>\n",
       "      <td>rbf linear</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>cubicSpline</td>\n",
       "      <td>cartesian</td>\n",
       "      <td>404868288</td>\n",
       "      <td>32 64 64 3</td>\n",
       "      <td>2023-03-13_10-01-01</td>\n",
       "      <td>2175</td>\n",
       "      <td>61</td>\n",
       "      <td>0.107339</td>\n",
       "      <td>0.333845</td>\n",
       "      <td>0.040534</td>\n",
       "      <td>0.014982</td>\n",
       "      <td>0.373001</td>\n",
       "      <td>0.043697</td>\n",
       "      <td>0.146862</td>\n",
       "      <td>4.557626</td>\n",
       "      <td>78.480322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>rbf linear</td>\n",
       "      <td>rbf linear</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>cubicSpline</td>\n",
       "      <td>cartesian</td>\n",
       "      <td>404868288</td>\n",
       "      <td>32 64 64 3</td>\n",
       "      <td>2023-03-13_10-01-01</td>\n",
       "      <td>2175</td>\n",
       "      <td>62</td>\n",
       "      <td>0.110234</td>\n",
       "      <td>0.335876</td>\n",
       "      <td>0.040185</td>\n",
       "      <td>0.014763</td>\n",
       "      <td>0.366949</td>\n",
       "      <td>0.043296</td>\n",
       "      <td>0.150095</td>\n",
       "      <td>4.572684</td>\n",
       "      <td>83.238856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>rbf linear</td>\n",
       "      <td>rbf linear</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>cubicSpline</td>\n",
       "      <td>cartesian</td>\n",
       "      <td>404868288</td>\n",
       "      <td>32 64 64 3</td>\n",
       "      <td>2023-03-13_10-01-01</td>\n",
       "      <td>2175</td>\n",
       "      <td>63</td>\n",
       "      <td>0.113123</td>\n",
       "      <td>0.337176</td>\n",
       "      <td>0.040007</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>0.370606</td>\n",
       "      <td>0.043416</td>\n",
       "      <td>0.149770</td>\n",
       "      <td>4.606118</td>\n",
       "      <td>83.198861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rbf_x       rbf_y  n  m       window        map       seed  \\\n",
       "0   rbf linear  rbf linear  4  4  cubicSpline  cartesian  404868288   \n",
       "1   rbf linear  rbf linear  4  4  cubicSpline  cartesian  404868288   \n",
       "2   rbf linear  rbf linear  4  4  cubicSpline  cartesian  404868288   \n",
       "3   rbf linear  rbf linear  4  4  cubicSpline  cartesian  404868288   \n",
       "4   rbf linear  rbf linear  4  4  cubicSpline  cartesian  404868288   \n",
       "..         ...         ... .. ..          ...        ...        ...   \n",
       "59  rbf linear  rbf linear  4  4  cubicSpline  cartesian  404868288   \n",
       "60  rbf linear  rbf linear  4  4  cubicSpline  cartesian  404868288   \n",
       "61  rbf linear  rbf linear  4  4  cubicSpline  cartesian  404868288   \n",
       "62  rbf linear  rbf linear  4  4  cubicSpline  cartesian  404868288   \n",
       "63  rbf linear  rbf linear  4  4  cubicSpline  cartesian  404868288   \n",
       "\n",
       "          arch             testFile  initialFrame  unrollStep  positionError  \\\n",
       "0   32 64 64 3  2023-03-13_10-01-01          2175           0       0.000390   \n",
       "1   32 64 64 3  2023-03-13_10-01-01          2175           1       0.000607   \n",
       "2   32 64 64 3  2023-03-13_10-01-01          2175           2       0.000942   \n",
       "3   32 64 64 3  2023-03-13_10-01-01          2175           3       0.001267   \n",
       "4   32 64 64 3  2023-03-13_10-01-01          2175           4       0.001649   \n",
       "..         ...                  ...           ...         ...            ...   \n",
       "59  32 64 64 3  2023-03-13_10-01-01          2175          59       0.101666   \n",
       "60  32 64 64 3  2023-03-13_10-01-01          2175          60       0.104504   \n",
       "61  32 64 64 3  2023-03-13_10-01-01          2175          61       0.107339   \n",
       "62  32 64 64 3  2023-03-13_10-01-01          2175          62       0.110234   \n",
       "63  32 64 64 3  2023-03-13_10-01-01          2175          63       0.113123   \n",
       "\n",
       "    velocityError  densityError  colorError  colorGradError  meshDensityError  \\\n",
       "0        0.020146      0.003873    0.001900        0.042205          0.004458   \n",
       "1        0.025437      0.002876    0.001341        0.026141          0.003357   \n",
       "2        0.029439      0.005146    0.002142        0.048802          0.005697   \n",
       "3        0.037243      0.005026    0.001940        0.043079          0.005669   \n",
       "4        0.047529      0.007829    0.002879        0.070483          0.008582   \n",
       "..            ...           ...         ...             ...               ...   \n",
       "59       0.336229      0.042118    0.014700        0.367478          0.044606   \n",
       "60       0.335782      0.041951    0.015280        0.382724          0.044812   \n",
       "61       0.333845      0.040534    0.014982        0.373001          0.043697   \n",
       "62       0.335876      0.040185    0.014763        0.366949          0.043296   \n",
       "63       0.337176      0.040007    0.014778        0.370606          0.043416   \n",
       "\n",
       "    meshVelocityError  meshDivergenceError   psdError  \n",
       "0            0.005987             0.262954   4.089778  \n",
       "1            0.008165             0.278887  10.122508  \n",
       "2            0.010492             0.329314  12.677175  \n",
       "3            0.013935             0.484648  16.561736  \n",
       "4            0.018717             0.688050  19.844995  \n",
       "..                ...                  ...        ...  \n",
       "59           0.147141             4.626566  79.619426  \n",
       "60           0.147635             4.628899  69.533739  \n",
       "61           0.146862             4.557626  78.480322  \n",
       "62           0.150095             4.572684  83.238856  \n",
       "63           0.149770             4.606118  83.198861  \n",
       "\n",
       "[64 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(unrollDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59b255",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "overallDict.to_csv('%s - testing.csv' % inputFile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
